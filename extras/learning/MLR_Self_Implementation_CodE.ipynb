{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XdXStL0Vxs0G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy.linalg import inv, pinv, LinAlgError\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(Xtemp,y)=datasets.fetch_california_housing(return_X_y=True)\n",
        "#20640 instances, 8 numeric features + target is  the median house value for California districts,\n",
        "#expressed in hundreds of thousands of dollars, no missing data\n",
        "X=np.ones((Xtemp.shape[0], Xtemp.shape[1]+1))\n",
        "print(type(X), X.shape)\n",
        "X[:,1:]=Xtemp;\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "print(\"Data:\")\n",
        "print(\"X:\", X.shape, \"y:\", y.shape, \"X_train:\", X_train.shape, \"X_test:\", X_test.shape, \"y_train:\", y_train.shape, \"y_test:\", y_test.shape);\n",
        "\n",
        "\n",
        "ss=StandardScaler();\n",
        "ss.fit(X_train[:,1:])\n",
        "X_train[:,1:]=ss.transform(X_train[:,1:])\n",
        "X_test[:,1:]=ss.transform(X_test[:,1:])\n",
        "\n",
        "#Linear Regression using Batch Gradient Descent using numpy\n",
        "print(\"#Linear Regression using Batch Gradient Descent using numpy#\");\n",
        "niterations=1000;\n",
        "m=X_train.shape[0]\n",
        "n=X_train.shape[1]\n",
        "lr=0.01\n",
        "#theta=np.random.uniform(0,1,size=(n))\n",
        "theta=np.zeros(n)\n",
        "update=np.zeros(n)\n",
        "for i in range(niterations):\n",
        "    ypred=np.dot(X_train,theta);\n",
        "    error=ypred - y_train; #be mindful of this order in difference\n",
        "    for j in range(n):\n",
        "        update[j]=np.sum(error*((X_train.T)[j]))\n",
        "    theta=theta-(lr)*(1/m)*update\n",
        "print(\"Thetas:\", theta)\n",
        "print(\"Thetas Shape:\", theta.shape)\n",
        "pred=np.dot(X_test,theta);\n",
        "print(\"MAE:\", metrics.mean_absolute_error(y_test,pred))\n",
        "print(\"MSE:\", metrics.mean_squared_error(y_test,pred))\n",
        "\n",
        "\n",
        "#Linear Regression using Normal Equation Method using numpy\n",
        "print(\"#Linear Regression using Normal Equation Method using numpy#\")\n",
        "theta=np.zeros(X_train.shape[1])\n",
        "try:\n",
        "    XTXi=inv(np.dot(X_train.T,X_train))\n",
        "except LinAlgError:\n",
        "    XTXi=pinv(np.dot(X_train.T,X_train))\n",
        "XTy=np.dot(X_train.T,y_train)\n",
        "theta=np.dot(XTXi,XTy)\n",
        "print(\"Thetas:\", theta)\n",
        "print(\"Thetas Shape:\", theta.shape)\n",
        "predictions=np.dot(theta,X_test.T)\n",
        "print(\"MAE:\", metrics.mean_absolute_error(y_true=y_test,y_pred=predictions))\n",
        "print(\"MSE:\", metrics.mean_squared_error(y_true=y_test,y_pred=predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKrnQfZqx2pL",
        "outputId": "24852a9e-a907-4f4b-fe52-1c2521b4a3fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (20640, 9)\n",
            "Data:\n",
            "X: (20640, 9) y: (20640,) X_train: (16512, 9) X_test: (4128, 9) y_train: (16512,) y_test: (4128,)\n",
            "#Linear Regression using Batch Gradient Descent using numpy#\n",
            "Thetas: [ 2.07185749  0.82894365  0.17853146 -0.13794939  0.15669182  0.01681517\n",
            " -0.04522857 -0.48705563 -0.45147126]\n",
            "Thetas Shape: (9,)\n",
            "MAE: 0.5476758462432642\n",
            "MSE: 0.5671852986082033\n",
            "#Linear Regression using Normal Equation Method using numpy#\n",
            "Thetas: [ 2.07194694  0.85438303  0.12254624 -0.29441013  0.33925949 -0.00230772\n",
            " -0.0408291  -0.89692888 -0.86984178]\n",
            "Thetas Shape: (9,)\n",
            "MAE: 0.5332001304956557\n",
            "MSE: 0.5558915986952441\n"
          ]
        }
      ]
    }
  ]
}